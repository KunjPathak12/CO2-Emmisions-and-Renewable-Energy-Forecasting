{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw1fQX8Enllo",
        "outputId": "832a1115-f49a-4a75-9aa8-e4df928fee20"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data= pd.read_csv('global-data-on-sustainable-energy.csv')\n",
        "missing_values = data.isnull().sum()\n",
        "length=len(data)\n",
        "missing_percentage = (missing_values / len(data)) * 100\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta5rc3Er7GJs",
        "outputId": "9ea8f701-0d46-4415-d1bc-65a276f234b7"
      },
      "outputs": [],
      "source": [
        "missing_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rVv33T6ns-3",
        "outputId": "efb90784-f87e-4150-949e-bfb5229f86da"
      },
      "outputs": [],
      "source": [
        "data_types = data.dtypes\n",
        "print(data_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Ne2ZLIbqbh"
      },
      "outputs": [],
      "source": [
        "def remove_functuation(density):\n",
        "    return density.replace(',','')\n",
        "data['Entity']=data['Entity'].astype(str)\n",
        "data['Density\\\\n(P/Km2)']=data['Density\\\\n(P/Km2)'].astype(str)\n",
        "data['Density\\\\n(P/Km2)']=data['Density\\\\n(P/Km2)'].apply(remove_functuation)\n",
        "data['Density\\\\n(P/Km2)']=data['Density\\\\n(P/Km2)'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUcskvIcbsFz",
        "outputId": "c2c7ac20-7980-4a8d-ed39-9a8ebab1911e"
      },
      "outputs": [],
      "source": [
        "#https://stackoverflow.com/questions/18689823/pandas-dataframe-replace-nan-values-with-average-of-columns\n",
        "#https://www.geeksforgeeks.org/remove-multiple-elements-from-a-list-in-python/\n",
        "columns=data.columns.tolist()\n",
        "feature_with_null=[column for column in columns if column not in ['Entity','Year','Primary energy consumption per capita (kWh/person)']]\n",
        "data.fillna(data[feature_with_null].mean(),inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "wZYAZnh1bt4N",
        "outputId": "6fd5d3d4-3aa7-4088-9e46-3fc034b60068"
      },
      "outputs": [],
      "source": [
        "df = data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtE36k7kbvTU",
        "outputId": "56e3e68d-9350-4d26-ba23-e1a32d71b500"
      },
      "outputs": [],
      "source": [
        "def rmOutliers(df, columns):\n",
        "    for column in columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "# List of columns to check for outliers\n",
        "columns_to_check = [\n",
        "    'Access to electricity (% of population)',\n",
        "    'Access to clean fuels for cooking',\n",
        "    'Renewable-electricity-generating-capacity-per-capita',\n",
        "    'Financial flows to developing countries (US $)',\n",
        "    'Renewable energy share in the total final energy consumption (%)',\n",
        "    'Electricity from fossil fuels (TWh)',\n",
        "    'Electricity from nuclear (TWh)',\n",
        "    'Electricity from renewables (TWh)',\n",
        "    'Primary energy consumption per capita (kWh/person)',\n",
        "    'Energy intensity level of primary energy (MJ/$2017 PPP GDP)',\n",
        "    'Value_co2_emissions_kt_by_country',\n",
        "    'Renewables (% equivalent primary energy)',\n",
        "    'gdp_growth',\n",
        "    'gdp_per_capita',\n",
        "]\n",
        "print (columns_to_check)\n",
        "\n",
        "# Apply the function to each group of entities\n",
        "df_cleaned = df.groupby('Entity').apply(lambda x: rmOutliers(x, columns_to_check)).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L16_C06rbxZB",
        "outputId": "c809f869-1b8a-442a-b761-2265083a1bb9"
      },
      "outputs": [],
      "source": [
        "print(f\"Total Outliers Removed considering for each country are:{df.count()-df_cleaned.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lqQi48EfrQd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVP_Fpqff2su"
      },
      "outputs": [],
      "source": [
        "scaler= StandardScaler()\n",
        "columns=data.select_dtypes(include=['float','integer']).columns\n",
        "data[columns]=scaler.fit_transform(data[columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mUclJOXg27P"
      },
      "outputs": [],
      "source": [
        "label_encoder=LabelEncoder()\n",
        "data['Entity']=label_encoder.fit_transform(data['Entity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVhE1fw8hKtn"
      },
      "outputs": [],
      "source": [
        "target_variables = ['Value_co2_emissions_kt_by_country', 'Renewable energy share in the total final energy consumption (%)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BPnb4hUvjGK"
      },
      "outputs": [],
      "source": [
        "# importing all the necessary models that are required to perform the regression\n",
        "#https://stackoverflow.com/questions/59489830/select-best-parameters-for-regression-model-using-gridsearch\n",
        "#https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained\n",
        "#https://www.analyticsvidhya.com/blog/2022/11/hyperparameter-tuning-using-randomized-search/\n",
        "#https://dev.to/newbie_coder/decision-tree-regression-a-comprehensive-guide-with-python-code-examples-and-hyperparameter-tuning-1f0f\n",
        "#https://stats.stackexchange.com/questions/269053/how-to-select-hyperparameters-for-svm-regression-after-grid-search\n",
        "#https://www.geeksforgeeks.org/random-forest-hyperparameter-tuning-in-python/\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import randint,uniform\n",
        "\n",
        "models={\n",
        "    'Linear Regression':LinearRegression(),\n",
        "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
        "    'Support Vector Regressor':SVR(),\n",
        "    'Random Forest Regressor':RandomForestRegressor()\n",
        "}\n",
        "param_grids = {\n",
        "    'Linear Regression': {\n",
        "              \"fit_intercept\": [True, False],\n",
        "             },\n",
        "    'Decision Tree Regression': {\n",
        "        'max_depth': [None, 5, 10],\n",
        "        'min_samples_split': randint(2, 10),\n",
        "        'min_samples_leaf': randint(1, 4)\n",
        "    },\n",
        "    'Support Vector Regressor': {\n",
        "        'kernel': ('linear', 'rbf','poly'), \n",
        "        'C':uniform(1.5, 10),\n",
        "        'gamma': uniform(1e-7, 1e-4),\n",
        "        'epsilon':uniform(0.1,0.5)\n",
        "    },\n",
        "    'Random Forest Regressor': {\n",
        "         'n_estimators':  randint(25, 150), \n",
        "         'max_features': ['sqrt', 'log2', None], \n",
        "         'max_depth':  randint(3, 9), \n",
        "         'max_leaf_nodes': randint(3, 9),\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "7OzVgCRgKOHg",
        "outputId": "69377960-b8b5-4b8f-d907-de6a168fae9d"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M23lRhvAuxhE",
        "outputId": "230104b2-8b37-4af9-ee2a-3d6b15b135cf"
      },
      "outputs": [],
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_model_with_base_parameters(models_dict):\n",
        "  for i in range(len(target_variables)):\n",
        "    print(f\"Below are the metrics for the target variable: {target_variables[i]}\")\n",
        "    for name, model in models_dict.items():\n",
        "      if name == 'Support Vector Regressor':\n",
        "            # Skipping RFE for SVR as it does not have the feature_importances_ or coef_ attribute\n",
        "            correlation_matrix =  data.select_dtypes(\"number\").corr()\n",
        "            target_features = correlation_matrix[target_variables[i]].drop(target_variables[i])\n",
        "            target_features = target_features[abs(target_features)>0.3].index.tolist()\n",
        "            X = data.drop(columns=target_features)\n",
        "            y = data[target_variables[i]]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "            model.fit(X_train, y_train)\n",
        "            #y_pred = model.predict(X_test)\n",
        "\n",
        "      else:\n",
        "            # Applying RFE for other models\n",
        "            rfe = RFE(estimator=model, n_features_to_select=10)\n",
        "            X = data.drop(columns=target_variables)\n",
        "            y = data[target_variables[i]]\n",
        "            fit = rfe.fit(X, y)\n",
        "            feature_ranking = pd.DataFrame({'Feature': X.columns, 'Ranking': fit.ranking_}).sort_values(by='Ranking')\n",
        "            final_features = feature_ranking[feature_ranking['Ranking'] == 1]['Feature'].to_list()\n",
        "            if 'Entity' not in final_features:\n",
        "                final_features.append('Entity')\n",
        "            X = X[final_features]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "            model.fit(X_train, y_train)\n",
        "            #y_pred = model.predict(X_test)\n",
        "      grid_search = RandomizedSearchCV(estimator=model,  param_distributions=param_grids[name], cv=3, scoring='r2',n_iter=4 )\n",
        "      grid_search.fit(X_train, y_train)\n",
        "            \n",
        "      best_model = grid_search.best_estimator_\n",
        "      y_pred = best_model.predict(X_test)\n",
        "            \n",
        "      \n",
        "\n",
        "      mse = mean_squared_error(y_test, y_pred)\n",
        "      mae = mean_absolute_error(y_test, y_pred)\n",
        "      r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "      print(f\"Model: {name}\")\n",
        "      print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "      print(f\"Mean squared error is: {mse}\")\n",
        "      print(f\"Mean absolute error is: {mae}\")\n",
        "      print(f\"R2 score error is: {r2}\")\n",
        "      print(\"\\n\")\n",
        "\n",
        "\n",
        "# now calling the function in order to get the outputs\n",
        "evaluate_model_with_base_parameters(models)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix =  data.select_dtypes(\"number\").corr()\n",
        "target_features = correlation_matrix[target_variables[0]].drop(target_variables[0])\n",
        "target_features = target_features[abs(target_features)>0.3].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=data[target_features]\n",
        "y=data[target_variables[0]]\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network=keras.Sequential([\n",
        "    layers.Input(shape=(4,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "'''\n",
        "import keras_tuner as kt\n",
        "tuner = kt.Hyperband(neural_network,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network.fit(X_train, y_train, epochs=40, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred=neural_network.predict(X_test)\n",
        "\n",
        "# calculating the scores based on the performance of the neural network\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Mean squared error (same as neural_network.evaluate()) is: {mse}\")\n",
        "print(f\"Mean absolute error is: {mae}\")\n",
        "print(f\"R2 score error is: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss = neural_network.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
